# Multilingual Healthcare Chatbot for Physical and Mental Wellbeing
Healthcare accessibility remains a challenge in many communities. This project addresses that gap by developing a multilingual, speech-enabled chatbot that provides reliable health information and emotional support. It combines intent-based response generation with a Large Language Model (LLM) for dynamic conversation handling, with a user-friendly Streamlit interface, the chatbot ensures inclusive, accessible, and real-time support for diverse user communities, including those with visual impairments.

**Key Features:**
- Hybrid Response System
    - Intent-based responses from a trained neural network on structured health datasets.
    - LLM integration for complex or unforeseen queries with multilingual support.
- Voice & Text Input/Output
    - Speech-to-text for voice queries.
    - Text-to-speech for spoken responsesâ€”ideal for visually impaired users.
- With the Multilingual Support the user can choose their preferred language for both input and output.
-  Provides sensitive responses to basic mental health concerns.

<h3>Screenshots</h3>
Chatbot Userinterface
<img src = "https://github.com/NASIKETHAN/Healthcare/blob/665ca485e5b2c9d268d0e2644aa70c310794c1a6/Screenshots/Screenshot%202025-03-16%20235507.png" width="610" height="400"><br>
Working of Chatbot using Voice Input
<img src = "https://github.com/NASIKETHAN/Healthcare/blob/665ca485e5b2c9d268d0e2644aa70c310794c1a6/Screenshots/Screenshot%202025-03-16%20235612.png" width="610" height="400"><br>
Working of Chatbot using Text Input
<img src = "https://github.com/NASIKETHAN/Healthcare/blob/665ca485e5b2c9d268d0e2644aa70c310794c1a6/Screenshots/Screenshot%202025-03-17%20142539.png" width="610" height="400"><br>
